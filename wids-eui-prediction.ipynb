{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T16:26:29.089303Z","iopub.execute_input":"2022-03-03T16:26:29.089684Z","iopub.status.idle":"2022-03-03T16:26:30.227957Z","shell.execute_reply.started":"2022-03-03T16:26:29.089568Z","shell.execute_reply":"2022-03-03T16:26:30.227132Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Read the training data \ndata = pd.read_csv('../input/widsdatathon2022/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:33.205542Z","iopub.execute_input":"2022-03-03T16:34:33.205857Z","iopub.status.idle":"2022-03-03T16:34:34.079688Z","shell.execute_reply.started":"2022-03-03T16:34:33.205826Z","shell.execute_reply":"2022-03-03T16:34:34.078814Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Initial look at the data","metadata":{}},{"cell_type":"markdown","source":"**Initial thoughts on the data**\n* The data is at year and building level \n* There are around 75k records in the training data\n* There is temperature information for each month as separate predictors. The energy usage can depend on the weather which can be determined by the months. So, having this information separately is good.\n* There's also information on the number of days the temperature was on the extreme ends (warm or cold)\n\n**Initial theories** \n* Older homes might have higher EUIs as most of the appliances might not be power efficient\n* Winter and summer months might see higher EUIs due to usage of heaters and A/Cs\n* Apartments with more floor area might see higher EUIs as more power will be required to heat up or cool down the apartment. ","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:35.972536Z","iopub.execute_input":"2022-03-03T16:34:35.973165Z","iopub.status.idle":"2022-03-03T16:34:36.013701Z","shell.execute_reply.started":"2022-03-03T16:34:35.973117Z","shell.execute_reply":"2022-03-03T16:34:36.012911Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:36.238159Z","iopub.execute_input":"2022-03-03T16:34:36.238733Z","iopub.status.idle":"2022-03-03T16:34:36.486237Z","shell.execute_reply.started":"2022-03-03T16:34:36.238689Z","shell.execute_reply":"2022-03-03T16:34:36.485443Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:36.487742Z","iopub.execute_input":"2022-03-03T16:34:36.487956Z","iopub.status.idle":"2022-03-03T16:34:36.494661Z","shell.execute_reply.started":"2022-03-03T16:34:36.487931Z","shell.execute_reply":"2022-03-03T16:34:36.493756Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:36.590475Z","iopub.execute_input":"2022-03-03T16:34:36.590770Z","iopub.status.idle":"2022-03-03T16:34:36.642468Z","shell.execute_reply.started":"2022-03-03T16:34:36.590738Z","shell.execute_reply":"2022-03-03T16:34:36.641630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"numerical_predictors = data.select_dtypes(include = [np.number]).columns\ncategorical_predictors = data.select_dtypes(exclude = [np.number]).columns","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:36.784099Z","iopub.execute_input":"2022-03-03T16:34:36.784368Z","iopub.status.idle":"2022-03-03T16:34:36.803588Z","shell.execute_reply.started":"2022-03-03T16:34:36.784339Z","shell.execute_reply":"2022-03-03T16:34:36.802147Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Data distribution of individual explanatory variables","metadata":{}},{"cell_type":"markdown","source":"Numerical variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 90))\nfor idx, col in enumerate(numerical_predictors):\n    plt.subplot(32, 2, idx + 1)\n    sns.histplot(data[col], kde = True)\n    plt.title(f'Distribution of {col}')\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.4, \n                    hspace=0.4)\nplt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:34:37.274287Z","iopub.execute_input":"2022-03-03T16:34:37.274595Z","iopub.status.idle":"2022-03-03T16:35:34.583753Z","shell.execute_reply.started":"2022-03-03T16:34:37.274560Z","shell.execute_reply":"2022-03-03T16:35:34.582760Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# year_built\nbins = [1900, 1920, 1940, 1960, 1980, 2000, 2021]\ngroups = pd.cut(data['year_built'], bins)\ngroups.value_counts().plot(kind = 'bar')\ngroups.value_counts()\n# Distribution of year_built across the years","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:34.585632Z","iopub.execute_input":"2022-03-03T16:35:34.586085Z","iopub.status.idle":"2022-03-03T16:35:34.835146Z","shell.execute_reply.started":"2022-03-03T16:35:34.586043Z","shell.execute_reply":"2022-03-03T16:35:34.834550Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Floor area\ndata.boxplot(column = 'floor_area', figsize = (10,7))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:34.836440Z","iopub.execute_input":"2022-03-03T16:35:34.837320Z","iopub.status.idle":"2022-03-03T16:35:35.160882Z","shell.execute_reply.started":"2022-03-03T16:35:34.837282Z","shell.execute_reply":"2022-03-03T16:35:35.160119Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Elevation\ndata.boxplot(column = 'ELEVATION', figsize = (10,7))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:35.162659Z","iopub.execute_input":"2022-03-03T16:35:35.162963Z","iopub.status.idle":"2022-03-03T16:35:35.491201Z","shell.execute_reply.started":"2022-03-03T16:35:35.162931Z","shell.execute_reply":"2022-03-03T16:35:35.490347Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n* The data distribution is skewed for most of the predictors\n* Over 30% of the buildings in the data are the oldest - are built in the range 1920-1940\n* The floor area is not really variable (steep peak for the mean) - most of the bigger values are outliers that makes sense. Same for elevation.\n* The temperature columns don't have a specific data distribution. The data seems really random with a lot of gaps in between.\n* The wind-related columns seem to have a huge gap in the middle before having some data that might be considered as outliers.\n","metadata":{}},{"cell_type":"markdown","source":"Categorical variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 20))\nfor idx, col in enumerate(categorical_predictors):\n    plt.subplot(2, 2, idx + 1)\n    data[col].value_counts().plot(kind = 'bar')\n    plt.title(f'Distribution of {col}')\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.4, \n                    hspace=0.4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:35.492295Z","iopub.execute_input":"2022-03-03T16:35:35.492521Z","iopub.status.idle":"2022-03-03T16:35:37.038072Z","shell.execute_reply.started":"2022-03-03T16:35:35.492492Z","shell.execute_reply":"2022-03-03T16:35:37.036679Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n* The dataset seems to have more data from State 6. Will this cause a bias? Probably shouldn't use this as a predictor. But, does EUI depend on government laws in some way?\n* Multifamily type seems to be the facility type with most records in the dataset.","metadata":{}},{"cell_type":"markdown","source":"#### Relation between site_eui and explanatory variables","metadata":{}},{"cell_type":"markdown","source":"Categorical variables","metadata":{}},{"cell_type":"code","source":"data.boxplot(by = 'building_class', column = 'site_eui', figsize = (10,7), showfliers = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:37.039598Z","iopub.execute_input":"2022-03-03T16:35:37.040125Z","iopub.status.idle":"2022-03-03T16:35:37.389330Z","shell.execute_reply.started":"2022-03-03T16:35:37.040082Z","shell.execute_reply":"2022-03-03T16:35:37.388685Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data.boxplot(by = 'State_Factor', column = 'site_eui', figsize = (10,7))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:37.390380Z","iopub.execute_input":"2022-03-03T16:35:37.390711Z","iopub.status.idle":"2022-03-03T16:35:37.821664Z","shell.execute_reply.started":"2022-03-03T16:35:37.390682Z","shell.execute_reply":"2022-03-03T16:35:37.820758Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data.boxplot(by = 'facility_type', column = 'site_eui', figsize = (20,10), rot = 90)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:37.823159Z","iopub.execute_input":"2022-03-03T16:35:37.823580Z","iopub.status.idle":"2022-03-03T16:35:40.001635Z","shell.execute_reply.started":"2022-03-03T16:35:37.823535Z","shell.execute_reply":"2022-03-03T16:35:40.000663Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n* The building class does see a difference in median for residential and commercial properties - but not by much. For categorical variables we want classes for which variance is high for response as that will help in differentiating between the values of response. The building class seems to be okay (not great) - can still include in the model.\n* The state data was biased in terms of the number of records in the dataset. Probably not a good idea to include this.\n* There is a lot of variability in the different classes of facility type but the data distribution for this was also highly biased. So, not sure how much this can be trusted. However, can create custom classes and divide the existing ones depending on the number of records or type of facility.","metadata":{}},{"cell_type":"markdown","source":"Numerical variables","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [20,100]\nplt.rcParams['figure.dpi'] = 100\nfig, axs = plt.subplots(32,2)\n\nfor itr, col in zip(axs.flat, numerical_predictors): # Flatten the axes or use ax[row,col] format in the loop\n    sns.regplot(x='site_eui', y=col, data=data, line_kws={\"color\":\"green\"}, ax=itr)\nfig.tight_layout()\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:35:40.002895Z","iopub.execute_input":"2022-03-03T16:35:40.003135Z","iopub.status.idle":"2022-03-03T16:45:32.779063Z","shell.execute_reply.started":"2022-03-03T16:35:40.003103Z","shell.execute_reply":"2022-03-03T16:45:32.777891Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Correlation between explanatory variables","metadata":{}},{"cell_type":"code","source":"# Find correlation \nfigsize=(100,150)\ndf_num = data[numerical_predictors]\ncorr = df_num.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize=(figsize))\nsns.heatmap(corr, mask = mask, cmap = 'vlag')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:32.783775Z","iopub.execute_input":"2022-03-03T16:45:32.784331Z","iopub.status.idle":"2022-03-03T16:45:42.145951Z","shell.execute_reply.started":"2022-03-03T16:45:32.784281Z","shell.execute_reply":"2022-03-03T16:45:42.144775Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"non_temp_predictors = ['Year_Factor', 'floor_area', 'year_built', 'energy_star_rating',\n       'ELEVATION', 'cooling_degree_days',\n       'heating_degree_days', 'precipitation_inches', 'snowfall_inches',\n       'snowdepth_inches', 'avg_temp', 'days_below_30F', 'days_below_20F',\n       'days_below_10F', 'days_below_0F', 'days_above_80F', 'days_above_90F',\n       'days_above_100F', 'days_above_110F', 'direction_max_wind_speed',\n       'direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog',\n       'site_eui']\n\nfigsize=(30,30)\ndf_num = data[non_temp_predictors]\ncorr = df_num.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize=(figsize))\nsns.heatmap(corr, mask = mask, cmap = 'coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:42.147566Z","iopub.execute_input":"2022-03-03T16:45:42.148041Z","iopub.status.idle":"2022-03-03T16:45:43.409141Z","shell.execute_reply.started":"2022-03-03T16:45:42.148000Z","shell.execute_reply":"2022-03-03T16:45:43.408494Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Observations** \nThe below columns seem to be highly correlated - \n* snowdepth_inches and snowfall_inches\n* direction_peak_wind_speed and direction_max_wind_speed\n* max_wind_speed and direction_max_wind_speed","metadata":{}},{"cell_type":"markdown","source":"#### Look for missing values","metadata":{}},{"cell_type":"code","source":"# Look for missing data \ndata.columns[data.isnull().any()]","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:43.410286Z","iopub.execute_input":"2022-03-03T16:45:43.410653Z","iopub.status.idle":"2022-03-03T16:45:43.447385Z","shell.execute_reply.started":"2022-03-03T16:45:43.410598Z","shell.execute_reply":"2022-03-03T16:45:43.446056Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data[['year_built', 'energy_star_rating', 'direction_max_wind_speed',\n       'direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog']].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:43.448574Z","iopub.execute_input":"2022-03-03T16:45:43.448842Z","iopub.status.idle":"2022-03-03T16:45:43.461878Z","shell.execute_reply.started":"2022-03-03T16:45:43.448811Z","shell.execute_reply":"2022-03-03T16:45:43.461158Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"The columns - 'direction_max_wind_speed', 'direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog' - have missing values for around 60% of the total data. So, ignoring these as predictors might be better than imputation or filtering the missing values. ","metadata":{}},{"cell_type":"markdown","source":"For the other 2 fields, year_built and energy_star_rating-\n* For energy_start_rating, there's still around 30% of data missing so imputation will be a better option than filtering out rows for which it's value is NaN. The decision to remove this column is something that needs to be considered later as from the description it feels like something that's worth a try. \n* Filtering out rows with year_built with missing value might work in this case or not using this field. The field will not be used directly thought; something like age of the building can be derived to be used as predictor.","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [20,10]\ndata['energy_star_rating'].plot.hist(bins=range(1,100))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:43.463808Z","iopub.execute_input":"2022-03-03T16:45:43.466911Z","iopub.status.idle":"2022-03-03T16:45:43.901248Z","shell.execute_reply.started":"2022-03-03T16:45:43.466857Z","shell.execute_reply":"2022-03-03T16:45:43.900654Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"data['year_built'].plot.hist(xlim = [1900,2022], bins = 500)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:43.902183Z","iopub.execute_input":"2022-03-03T16:45:43.902721Z","iopub.status.idle":"2022-03-03T16:45:45.115629Z","shell.execute_reply.started":"2022-03-03T16:45:43.902687Z","shell.execute_reply":"2022-03-03T16:45:45.114699Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"data[['year_built', 'energy_star_rating']].describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:45.117017Z","iopub.execute_input":"2022-03-03T16:45:45.117436Z","iopub.status.idle":"2022-03-03T16:45:45.144399Z","shell.execute_reply.started":"2022-03-03T16:45:45.117388Z","shell.execute_reply":"2022-03-03T16:45:45.143461Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Data transformation to handle missing values\ndata = data[data['year_built'].notnull()].copy()\ndata['energy_star_rating'].fillna(data['energy_star_rating'].mean(), inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:45.145951Z","iopub.execute_input":"2022-03-03T16:45:45.146256Z","iopub.status.idle":"2022-03-03T16:45:45.182329Z","shell.execute_reply.started":"2022-03-03T16:45:45.146214Z","shell.execute_reply":"2022-03-03T16:45:45.181626Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from datetime import date\ndata['building_age'] = data.apply(lambda x: date.today().year - x['year_built'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:45.183482Z","iopub.execute_input":"2022-03-03T16:45:45.183858Z","iopub.status.idle":"2022-03-03T16:45:46.576122Z","shell.execute_reply.started":"2022-03-03T16:45:45.183814Z","shell.execute_reply":"2022-03-03T16:45:46.575344Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Model Selection","metadata":{}},{"cell_type":"markdown","source":"Planning to use all the columns for now except - facility_type (needs more analysis),year_built,'direction_max_wind_speed', 'direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog'","metadata":{}},{"cell_type":"code","source":"# Transform categorical variables\ndata = pd.get_dummies(data, columns = ['building_class'], drop_first = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:46.577290Z","iopub.execute_input":"2022-03-03T16:45:46.577524Z","iopub.status.idle":"2022-03-03T16:45:46.624809Z","shell.execute_reply.started":"2022-03-03T16:45:46.577494Z","shell.execute_reply":"2022-03-03T16:45:46.623978Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Data Transformation before fitting model\nall_predictors = set(data.columns)\nremove_predictors = ['id','Year_Factor','State_Factor', 'facility_type','year_built','direction_max_wind_speed','direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog', 'site_eui']\npredictors = list(all_predictors - set(remove_predictors))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:46.625979Z","iopub.execute_input":"2022-03-03T16:45:46.626233Z","iopub.status.idle":"2022-03-03T16:45:46.631667Z","shell.execute_reply.started":"2022-03-03T16:45:46.626205Z","shell.execute_reply":"2022-03-03T16:45:46.630576Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nfrom sklearn.metrics import mean_squared_error, r2_score\n\nX = data[predictors]\ny = data['site_eui']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:46.633231Z","iopub.execute_input":"2022-03-03T16:45:46.633717Z","iopub.status.idle":"2022-03-03T16:45:46.891776Z","shell.execute_reply.started":"2022-03-03T16:45:46.633674Z","shell.execute_reply":"2022-03-03T16:45:46.891032Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(y_test, y_pred):\n    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    print(f'RMSE : {RMSE}')\n    print(f'R2 : {r2}')\n    n = X_test.shape[0]\n    p = X_test.shape[1]\n    adj_r2 = 1 - ((1-r2)*(n-1)/(n-p-1))\n    print(f'Adjusted-R2 : {adj_r2}')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:46.893304Z","iopub.execute_input":"2022-03-03T16:45:46.893826Z","iopub.status.idle":"2022-03-03T16:45:46.901356Z","shell.execute_reply.started":"2022-03-03T16:45:46.893781Z","shell.execute_reply":"2022-03-03T16:45:46.900475Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Multilinear regression","metadata":{}},{"cell_type":"markdown","source":"The basic model that can be tried is **Multi-Linear Regression** to fit a line through each predictor and response plot an get coefficients that indicates the change in response with unit change in each predictor","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:46.902981Z","iopub.execute_input":"2022-03-03T16:45:46.903351Z","iopub.status.idle":"2022-03-03T16:45:47.132215Z","shell.execute_reply.started":"2022-03-03T16:45:46.903306Z","shell.execute_reply":"2022-03-03T16:45:47.131292Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"for name, coef in zip(predictors, lr_model.coef_):\n    print(f'{name}: {coef}')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:47.137738Z","iopub.execute_input":"2022-03-03T16:45:47.138302Z","iopub.status.idle":"2022-03-03T16:45:47.157456Z","shell.execute_reply.started":"2022-03-03T16:45:47.138249Z","shell.execute_reply":"2022-03-03T16:45:47.156660Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(f'Intercept : {lr_model.intercept_}')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:47.159152Z","iopub.execute_input":"2022-03-03T16:45:47.159742Z","iopub.status.idle":"2022-03-03T16:45:47.166076Z","shell.execute_reply.started":"2022-03-03T16:45:47.159700Z","shell.execute_reply":"2022-03-03T16:45:47.165075Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"pred_values_lr = lr_model.predict(X_test)\nevaluate_model(y_test,pred_values_lr )","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:47.168025Z","iopub.execute_input":"2022-03-03T16:45:47.168733Z","iopub.status.idle":"2022-03-03T16:45:47.212430Z","shell.execute_reply.started":"2022-03-03T16:45:47.168687Z","shell.execute_reply":"2022-03-03T16:45:47.211112Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"#Random Forest \n\nfrom sklearn.ensemble import RandomForestRegressor\n# Values after using grid search\nrf_model = RandomForestRegressor(n_estimators=500, min_samples_split = 2, min_samples_leaf = 2, max_depth = 15)\nrf_model.fit(X_train, y_train)\n\npred_values_rf = rf_model.predict(X_test)\nevaluate_model(y_test,pred_values_rf )","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:45:47.215477Z","iopub.execute_input":"2022-03-03T16:45:47.217949Z","iopub.status.idle":"2022-03-03T16:50:44.242254Z","shell.execute_reply.started":"2022-03-03T16:45:47.217888Z","shell.execute_reply":"2022-03-03T16:50:44.241364Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boost","metadata":{}},{"cell_type":"code","source":"# Gradient boost \nfrom sklearn.ensemble import GradientBoostingRegressor\ngb_model = GradientBoostingRegressor(n_estimators=500)\ngb_model.fit(X_train, y_train)\n\npred_values_gb = gb_model.predict(X_test)\nevaluate_model(y_test, pred_values_gb)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:50:44.248187Z","iopub.execute_input":"2022-03-03T16:50:44.248655Z","iopub.status.idle":"2022-03-03T16:52:18.044450Z","shell.execute_reply.started":"2022-03-03T16:50:44.248581Z","shell.execute_reply":"2022-03-03T16:52:18.043403Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"##### Grid search code","metadata":{}},{"cell_type":"code","source":"# Grid search for Random Forest \n#forest = RandomForestRegressor(random_state = 1)\n#from sklearn.model_selection import GridSearchCV\n#n_estimators = [100, 300, 500]\n#max_depth = [5, 8, 15]\n#min_samples_split = [2, 5, 10]\n#min_samples_leaf = [2, 5, 10] \n\n#hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n#              min_samples_split = min_samples_split, \n#             min_samples_leaf = min_samples_leaf)\n\n#gridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, \n#                      n_jobs = -1, scoring = 'neg_root_mean_squared_error')\n#bestF = gridF.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bestF.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.metrics import SCORERS\n#sorted(SCORERS.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grid search for Gradient Boost\nforest = GradientBoostingRegressor(random_state = 1)\nfrom sklearn.model_selection import GridSearchCV\nn_estimators = [100, 300, 500]\nmax_depth = [5, 8, 15]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [2, 5, 10] \nlearning_rate = [0.1, 0.01, 1, 0.5]\n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf, learning_rate = learning_rate)\n\ngridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, \n                      n_jobs = -1, scoring = 'neg_root_mean_squared_error')\nbestF = gridF.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestF.best_params_","metadata":{},"execution_count":null,"outputs":[]}]}